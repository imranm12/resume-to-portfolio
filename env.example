# ─── LLM Provider Switch ──────────────────────────────────────────────────────
# Set to "ollama" for local development (free, no API key needed)
# Set to "groq" for production deployment (free tier, fast, needs API key)
LLM_PROVIDER=ollama

# ─── Ollama settings (used when LLM_PROVIDER=ollama) ─────────────────────────
OLLAMA_MODEL=llama3.1
OLLAMA_BASE_URL=http://localhost:11434

# ─── Groq settings (used when LLM_PROVIDER=groq) ─────────────────────────────
# Get your free API key at: https://console.groq.com
# Free tier: 14,400 requests/day — plenty for a side project
GROQ_API_KEY=
GROQ_MODEL=llama-3.1-8b-instant

# ─── GitHub enrichment (optional) ────────────────────────────────────────────
# Enables pinned repo fetching. Get token at: https://github.com/settings/tokens
# Scopes needed: read:user, public_repo
GITHUB_TOKEN=

# ─── Frontend URL (for CORS) ──────────────────────────────────────────────────
# Local dev:
FRONTEND_URL=http://localhost:3000
# Production (update after deploying frontend to Vercel):
# FRONTEND_URL=https://your-app.vercel.app
